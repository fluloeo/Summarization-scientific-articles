{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14437418,"sourceType":"datasetVersion","datasetId":9221908}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/fluloeo/sum-art?scriptVersionId=291034435\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport ast\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-10T02:31:30.320782Z","iopub.execute_input":"2026-01-10T02:31:30.321366Z","iopub.status.idle":"2026-01-10T02:31:30.327276Z","shell.execute_reply.started":"2026-01-10T02:31:30.321339Z","shell.execute_reply":"2026-01-10T02:31:30.326558Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/articles/df_dict_test.csv\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"# !pip install -U deepeval\n\n# # Настройка API-ключа (используйте Add-ons -> Secrets в Kaggle для безопасности)\n# # import os\n# # os.environ['OPENAI_API_KEY'] = ''  # Или используйте Secrets","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from deepeval import evaluate\n# from deepeval.test_case import LLMTestCase\n# from deepeval.metrics import SummarizationMetric\n# from deepeval.metrics import GEval\n# from deepeval.test_case import LLMTestCaseParams\n# # Ваши данные: оригинал статьи и её сводка\n# original_text = \"\"\"Длинный текст вашей научной статьи здесь...\"\"\"\n# generated_summary = \"\"\"Сгенерированная моделью суммаризация здесь...\"\"\"\n\n# # Создание тест-кейса и метрики\n# test_case = LLMTestCase(input=original_text, actual_output=generated_summary)\n# # Используйте assessment_questions для проверки конкретных аспектов\n# metric = SummarizationMetric(\n#     threshold=0.7,  # Порог успешного прохождения (0-1)\n#     model=\"gpt-4o-mini\",  # Модель-судья (можно изменить)\n#     assessment_questions=[  # Пример вопросов для научной статьи\n#         \"Упомянута ли в сводке гипотеза исследования?\",\n#         \"Описан ли использованный метод?\",\n#         \"Приведены ли основные численные результаты?\",\n#         \"Обсуждаются ли ограничения исследования?\"\n#     ],\n#     include_reason=True  # Чтобы получить объяснение оценки\n# )\n\n# # Запуск оценки\n# evaluate(test_cases=[test_case], metrics=[metric])\n# # После выполнения можно вывести детали:\n# print(f\"Итоговый балл: {metric.score}\")\n# print(f\"Причина: {metric.reason}\")\n# print(f\"Детализация: Coverage={metric.score_breakdown['coverage_score']}, Alignment={metric.score_breakdown['alignment_score']}\")\n\n\n\n# # Определение кастомной метрики для научной суммаризации\n# scientific_quality_metric = GEval(\n#     name=\"Научная качественность\",\n#     criteria=\"\"\"Оцени сводку научной статьи по следующим критериям:\n#     1. **Точность**: Все факты, цифры и выводы точно соответствуют оригиналу.\n#     2. **Полнота**: Отражены цель, методы, ключевые результаты и вывод.\n#     3. **Ясность**: Логичная структура, понятный язык без жаргона.\n#     4. **Значимость**: Выделены наиболее важные и новые аспекты исследования.\"\"\",\n#     # Шаги рассуждения для модели-судьи (опционально, но повышает согласованность)\n#     evaluation_steps=[\n#         \"Внимательно прочти оригинал статьи и сводку.\",\n#         \"По пунктам проверь соответствие сводки критериям Точности, Полноты, Ясности и Значимости.\",\n#         \"Присвой итоговый балл от 1 до 10, где 10 - идеальная сводка.\",\n#     ],\n#     # Какие параметры тест-кейса использовать (original text = input, summary = actual_output)\n#     evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT],\n#     model=\"gpt-4\",  # Можно использовать более мощную модель для сложных оценок\n#     threshold=0.7\n# )\n\n# # Создание тест-кейса и запуск оценки (также через evaluate или .measure())\n# test_case = LLMTestCase(input=original_text, actual_output=generated_summary)\n# scientific_quality_metric.measure(test_case)\n# print(f\"Балл: {scientific_quality_metric.score}\")\n# print(f\"Обоснование оценки: {scientific_quality_metric.reason}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def append_summary_to_file(final_summary, filename='all_summaries.txt', directory='/kaggle/working/'):\n    \"\"\"\n    Добавляет текст final_summary в конец указанного файла.\n\n    Параметры:\n        final_summary (str): Текст сводки для добавления в файл.\n        filename (str): Имя файла (по умолчанию 'all_summaries.txt').\n        directory (str): Путь к папке для сохранения (по умолчанию рабочая директория Kaggle).\n    \"\"\"\n    # Формируем полный путь к файлу\n    filepath = directory + filename\n\n    # Открываем файл в режиме добавления ('a') с кодировкой UTF-8\n    # Режим 'a' создаст файл, если его нет, и допишет текст в конец, если он существует\n    with open(filepath, 'a', encoding='utf-8') as file:\n        # Записываем текст и добавляем перенос строки для разделения записей\n        file.write(final_summary + '\\n')\n\n    print(f'Текст добавлен в файл: {filepath}')\n\n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T23:29:08.783687Z","iopub.execute_input":"2026-01-09T23:29:08.784435Z","iopub.status.idle":"2026-01-09T23:29:08.788933Z","shell.execute_reply.started":"2026-01-09T23:29:08.784405Z","shell.execute_reply":"2026-01-09T23:29:08.788324Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/articles/df_dict_test.csv')\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T23:29:11.744661Z","iopub.execute_input":"2026-01-09T23:29:11.74518Z","iopub.status.idle":"2026-01-09T23:29:11.908108Z","shell.execute_reply.started":"2026-01-09T23:29:11.745152Z","shell.execute_reply":"2026-01-09T23:29:11.907399Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"            id                                              title  \\\n0   1602.04402  balanced truncation of linear time-invariant s...   \n1   1611.01462  tying word vectors and word classifiers: a los...   \n2   1611.04496  multi-view recurrent neural acoustic word embe...   \n3   1808.00560  compressible spectral mixture kernels with spa...   \n4   2111.00405  limitations of the macaulay matrix approach fo...   \n..         ...                                                ...   \n95  2307.14341  virtual mirrors: non-line-of-sight imaging bey...   \n96  2307.14354  learned gridification for efficient point clou...   \n97  2307.14362  learnable wavelet neural networks for cosmolog...   \n98  2307.14392  human-centric scene understanding for 3d large...   \n99  2309.03177  3d object positioning using differentiable mul...   \n\n                                             abstract  \\\n0   this paper discusses model order reduction of ...   \n1   recurrent neural networks have been very succe...   \n2   recent work has begun exploring neural acousti...   \n3   spectral mixture (sm) kernels comprise a power...   \n4   recently chen and gao~\\cite{chengao2017} propo...   \n..                                                ...   \n95  non-line-of-sight (nlos) imaging methods are c...   \n96  neural operations that rely on neighborhood in...   \n97  convolutional neural networks (cnns) have been...   \n98  human-centric scene understanding is significa...   \n99  this article describes a multi-modal method us...   \n\n                                            dict_test  \n0   {'I. INTRODUCTION AND PROBLEM FORMULATIONS': '...  \n1   {'INTRODUCTION': \"Neural network models have r...  \n2   {'INTRODUCTION': 'Word embeddings-continuous-v...  \n3   {'Introduction': \"Gaussian processes (GPs) con...  \n4   {'Introduction': 'Solving systems of multivari...  \n..                                                ...  \n95  {'Computed image of': 'T-shaped object from a ...  \n96  {'Introduction': 'Point clouds provide sparse ...  \n97  {'Introduction': 'The process of extracting in...  \n98  {'Introduction': 'Human-centric scene understa...  \n99  {'I. INTRODUCTION': \"Differentiable rendering ...  \n\n[100 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>abstract</th>\n      <th>dict_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1602.04402</td>\n      <td>balanced truncation of linear time-invariant s...</td>\n      <td>this paper discusses model order reduction of ...</td>\n      <td>{'I. INTRODUCTION AND PROBLEM FORMULATIONS': '...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1611.01462</td>\n      <td>tying word vectors and word classifiers: a los...</td>\n      <td>recurrent neural networks have been very succe...</td>\n      <td>{'INTRODUCTION': \"Neural network models have r...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1611.04496</td>\n      <td>multi-view recurrent neural acoustic word embe...</td>\n      <td>recent work has begun exploring neural acousti...</td>\n      <td>{'INTRODUCTION': 'Word embeddings-continuous-v...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1808.00560</td>\n      <td>compressible spectral mixture kernels with spa...</td>\n      <td>spectral mixture (sm) kernels comprise a power...</td>\n      <td>{'Introduction': \"Gaussian processes (GPs) con...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2111.00405</td>\n      <td>limitations of the macaulay matrix approach fo...</td>\n      <td>recently chen and gao~\\cite{chengao2017} propo...</td>\n      <td>{'Introduction': 'Solving systems of multivari...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>2307.14341</td>\n      <td>virtual mirrors: non-line-of-sight imaging bey...</td>\n      <td>non-line-of-sight (nlos) imaging methods are c...</td>\n      <td>{'Computed image of': 'T-shaped object from a ...</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>2307.14354</td>\n      <td>learned gridification for efficient point clou...</td>\n      <td>neural operations that rely on neighborhood in...</td>\n      <td>{'Introduction': 'Point clouds provide sparse ...</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>2307.14362</td>\n      <td>learnable wavelet neural networks for cosmolog...</td>\n      <td>convolutional neural networks (cnns) have been...</td>\n      <td>{'Introduction': 'The process of extracting in...</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>2307.14392</td>\n      <td>human-centric scene understanding for 3d large...</td>\n      <td>human-centric scene understanding is significa...</td>\n      <td>{'Introduction': 'Human-centric scene understa...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>2309.03177</td>\n      <td>3d object positioning using differentiable mul...</td>\n      <td>this article describes a multi-modal method us...</td>\n      <td>{'I. INTRODUCTION': \"Differentiable rendering ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"*Пример для одной статьи:*","metadata":{}},{"cell_type":"markdown","source":"статьи 12 8 7 имеют проблемы с большим количеством чанков\n","metadata":{}},{"cell_type":"code","source":"from typing import List\n\ndef get_token_length(text: str) -> int:\n    return len(tokenizer.encode(text))\n\ndef merge_small_chunks_by_tokens(chunks: List[str], min_tokens: int) -> List[str]:\n    \"\"\"\n    Объединяет чанки, если их длина в ТОКЕНАХ меньше min_tokens.\n    Слияние происходит с наименьшим соседом (по количеству токенов).\n    \"\"\"\n    processed_chunks = chunks[:]\n    separator = \" \" # Разделитель при склейке\n    \n    i = 0\n    while i < len(processed_chunks):\n        current_chunk = processed_chunks[i]\n        current_len = get_token_length(current_chunk)\n        if current_len >= min_tokens:\n            i += 1\n            continue\n        if len(processed_chunks) == 1:\n            break\n        if i > 0:\n            left_len = get_token_length(processed_chunks[i-1])\n        else:\n            left_len = float('inf')\n\n        if i < len(processed_chunks) - 1:\n            right_len = get_token_length(processed_chunks[i+1])\n        else:\n            right_len = float('inf')\n        if left_len < right_len:\n            # print(f\"DEBUG: Слияние '{processed_chunks[i][:20]}...' ВЛЕВО (Tokens: {current_len} + {left_len})\")\n            \n            processed_chunks[i-1] = processed_chunks[i-1] + separator + processed_chunks[i]\n            processed_chunks.pop(i)\n            i -= 1 \n        else:\n            # print(f\"DEBUG: Слияние '{processed_chunks[i][:20]}...' ВПРАВО (Tokens: {current_len} + {right_len})\")\n            processed_chunks[i] = processed_chunks[i] + separator + processed_chunks[i+1]\n            processed_chunks.pop(i+1)\n    return processed_chunks\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T02:49:38.688742Z","iopub.execute_input":"2026-01-10T02:49:38.689493Z","iopub.status.idle":"2026-01-10T02:49:38.696417Z","shell.execute_reply.started":"2026-01-10T02:49:38.689464Z","shell.execute_reply":"2026-01-10T02:49:38.695758Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"def merge_chunks_in_dataset(df=df, min_tokens=100, n=100, n_threshold = 10):\n    data = pd.DataFrame(columns=['chunks'])\n    max_len_chunks = []\n    max_size_chunks = []\n    min_size_chunks = []\n    for i in range(n):\n        data_dict = ast.literal_eval(df['dict_test'].iloc[i])\n        tokens_chunks_list_0 = list(map(lambda x: get_token_length(x), list(data_dict.values())))\n        if len(tokens_chunks_list_0)>n_threshold or min(tokens_chunks_list_0)<min_tokens:\n            final_chunks = merge_small_chunks_by_tokens(list(data_dict.values()), min_tokens=min_tokens)\n            # print(f\"\\nКонечное количество чанков: {len(final_chunks)}\\n\")\n            tokens_chunks_list = list(map(lambda x: get_token_length(x), final_chunks))\n            # print('Максимальный размер чанка',max(tokens_chunks_list),'\\n')\n            max_len_chunks.append(len(final_chunks))\n            max_size_chunks.append(max(tokens_chunks_list))\n            min_size_chunks.append(min(tokens_chunks_list))\n            data.loc[len(data)] = [final_chunks]\n        else:\n            print(\"Ничего не меняем, кол-во чанков, мин токенов\", len(tokens_chunks_list_0),min(tokens_chunks_list_0))\n            data.loc[len(data)] = [data_dict]\n    print('Максимальное Кол-во чанков из всех статей\\n',(max(max_len_chunks)))\n    print('Минимальное Кол-во чанков из всех статей\\n',(min(max_len_chunks)))\n    print('Максимальный размер чанка из всех статей\\n',max(max_size_chunks))\n    print('Минимальный размер чанка из всех статей\\n',min(min_size_chunks))\n    return data\ndata = merge_chunks_in_dataset(df=df, min_tokens=700, n=20,n_threshold = 10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T03:12:11.505282Z","iopub.execute_input":"2026-01-10T03:12:11.506052Z","iopub.status.idle":"2026-01-10T03:12:13.971299Z","shell.execute_reply.started":"2026-01-10T03:12:11.50602Z","shell.execute_reply":"2026-01-10T03:12:13.970681Z"}},"outputs":[{"name":"stdout","text":"Максимальное Кол-во чанков из всех статей\n 14\nМинимальное Кол-во чанков из всех статей\n 5\nМаксимальный размер чанка из всех статей\n 3331\nМинимальный размер чанка из всех статей\n 706\n","output_type":"stream"}],"execution_count":117},{"cell_type":"code","source":"data.tail()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T03:03:15.221632Z","iopub.execute_input":"2026-01-10T03:03:15.222034Z","iopub.status.idle":"2026-01-10T03:03:15.231224Z","shell.execute_reply.started":"2026-01-10T03:03:15.222008Z","shell.execute_reply":"2026-01-10T03:03:15.230474Z"}},"outputs":[{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"                                               chunks\n15  [Humanoid robots have gained prominence for th...\n16  [In recent years, transformer models have show...\n17  [Disinformation is a recurring threat to socie...\n18  [Voice conversion (VC) is a technology that co...\n19  [Sequential recommendation processes sequences...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chunks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <td>[Humanoid robots have gained prominence for th...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>[In recent years, transformer models have show...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>[Disinformation is a recurring threat to socie...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>[Voice conversion (VC) is a technology that co...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>[Sequential recommendation processes sequences...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":100},{"cell_type":"code","source":"!pip install -U bitsandbytes accelerate transformers -q\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nimport torch\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\"\n)\ntokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-4B-Instruct-2507\")\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"Qwen/Qwen3-4B-Instruct-2507\",\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    trust_remote_code=True\n)\n\ntorch.cuda.empty_cache()\n!pip install langchain==0.0.208  -q\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n!pip install rouge-score evaluate -q\nfrom rouge_score import rouge_scorer\nimport evaluate\nrouge = evaluate.load('rouge')\n\n!pip install bert-score -q\nfrom bert_score import BERTScorer\n\nscorer = BERTScorer(lang=\"en\", model_type=\"bert-base-multilingual-cased\")\n\n!pip install longdocfactscore -q\nimport nltk\nnltk.download('punkt_tab')\nnltk.download('punkt')\nfrom longdocfactscore.ldfacts import LongDocFACTScore\nldfacts_scorer = LongDocFACTScore(device=device)\nfrom tqdm.notebook import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T23:29:35.111545Z","iopub.execute_input":"2026-01-09T23:29:35.111944Z","iopub.status.idle":"2026-01-09T23:32:22.420183Z","shell.execute_reply.started":"2026-01-09T23:29:35.111911Z","shell.execute_reply":"2026-01-09T23:32:22.418927Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hcuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c287e73746ba43209c6e52e96f56d5e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24f4c126519343cfab0e923cab6a57ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd873ebcae004a59a5f012b01dbce28f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63d9149e42794bd48daecb2f24bb0a86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"407efd7d7af6469781a524825c7e46c8"}},"metadata":{}},{"name":"stderr","text":"2026-01-09 23:30:18.425984: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768001418.879680      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768001419.002851      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768001420.046221      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768001420.046245      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768001420.046248      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768001420.046250      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1ae69d3887d4cbf87cda2bdd0a13eda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"389c0263dc9c400c8c2114b74fc0d905"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1e64b2f1b2f4778a03dc0215206dbcb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/99.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec43b894f1234f3ebf741bff2c0fd5b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1a0e8b3dcd54e47ab844de26b467b91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dce6af79e5a54d999d402db7c014b74f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/238 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5f97243feee4e709898728939b168a0"}},"metadata":{}},{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.1/155.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nsigstore 4.1.0 requires pydantic<3,>=2, but you have pydantic 1.10.26 which is incompatible.\nsigstore-models 0.0.5 requires pydantic>=2.11.7, but you have pydantic 1.10.26 which is incompatible.\nsigstore-rekor-types 0.0.18 requires pydantic[email]<3,>=2, but you have pydantic 1.10.26 which is incompatible.\nydata-profiling 4.18.0 requires pydantic<3,>=2, but you have pydantic 1.10.26 which is incompatible.\nxmanager 0.7.1 requires sqlalchemy==1.2.19, but you have sqlalchemy 2.0.45 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires jupyter-server==2.14.0, but you have jupyter-server 2.12.5 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\njaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nthinc 8.3.6 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.26 which is incompatible.\nopencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nopencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\njax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\nlangchain-core 0.3.79 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.26 which is incompatible.\ncudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ngradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 1.10.26 which is incompatible.\nalbumentations 2.0.8 requires pydantic>=2.9.2, but you have pydantic 1.10.26 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nopencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\npytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-genai 1.45.0 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.26 which is incompatible.\npydantic-settings 2.11.0 requires pydantic>=2.7.0, but you have pydantic 1.10.26 which is incompatible.\nmcp 1.18.0 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 1.10.26 which is incompatible.\npylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"851a3e16393543158c9fb4184d6d5235"}},"metadata":{}},{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b13e63453d2f4b14816a48f9e66a3551"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97b3082608cd48b4aa28df4adc714768"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f7e4e826bfd412daf1a09c0a7ee9633"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a8158af4f8f446fa05eb6021509f491"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a82cb9ade3a4138800ee725f1ee13ff"}},"metadata":{}},{"name":"stderr","text":"[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa73d1df3e84409587a8c991bd50c134"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"462dea9dd223466990163e152ac430ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e402b7524bd42f385265a1ebdc04d9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd8fe49362964d70a4d5c9b2ca27e731"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2825a652f685479bafd5a5bdae22ac5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc8139a6f1494f0894f72f9d46ff7916"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/399 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"473c9b47f00641d3b4739ce415f64276"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"497bfa629703419490ccdbd2eb115918"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48e71ba680034d87882437e3854be545"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4f64a60b6e44b38894a75a259563511"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"543e3f6928754ce58c260ee3f4d38524"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9a9eacf7ccb46918e09939fb5db6651"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"583566525cf541b8bd2ad9946471386e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"200246d3b7e948328986d2c9602c86c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06948f79dab94ea18787be475364ab24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e516fd58565462eb726d55520f3b467"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b5ec6171f964ecabbab4981a490b456"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a022c0a7ba244a1f8893924afa3e7186"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cbb28d13169499fa60208fb9489fffb"}},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"Функция для того чтобы отправить инструкцию модели","metadata":{}},{"cell_type":"code","source":"def qwen(article, prompt, max_tokens):\n    torch.cuda.empty_cache()\n    final_prompt = f\"{prompt}:\\n\\n{article}\"\n    messages = [{\"role\": \"user\", \"content\": final_prompt}]\n    model.eval()\n    with torch.no_grad():\n        inputs = tokenizer.apply_chat_template(\n            messages,\n            add_generation_prompt=True,\n            tokenize=True,\n            return_dict=True,\n            return_tensors=\"pt\",\n            truncation=False\n        ).to(model.device)\n        outputs = model.generate(\n            **inputs,\n            max_new_tokens=max_tokens,\n            do_sample=False\n        )\n    final_summary = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n    return final_summary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T23:32:52.395443Z","iopub.execute_input":"2026-01-09T23:32:52.396179Z","iopub.status.idle":"2026-01-09T23:32:52.402076Z","shell.execute_reply.started":"2026-01-09T23:32:52.396147Z","shell.execute_reply":"2026-01-09T23:32:52.401387Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"Функция для обработки чанков статьи, встроенный text_splitter можно отключить","metadata":{}},{"cell_type":"code","source":"def summarize(article, prompt_0, prompt_1,chunk_size=1500, max_tokens_0=700, max_tokens_1=700, text_splitter = True):\n    torch.cuda.empty_cache()\n    if text_splitter:\n        text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n            tokenizer=tokenizer,\n            chunk_size=chunk_size,\n            chunk_overlap=chunk_size//20,\n            separators=[\"\\n\\n\", \"\\n\", \". \"],\n            keep_separator=True\n        )\n        article_chunks = text_splitter.split_text(article)\n    else:\n        article_chunks = article\n    summaries = []\n    for i, chunk in tqdm(enumerate(article_chunks), total=len(article_chunks)):\n        try:\n            chunk_summary = qwen(article=chunk, prompt=prompt_0, max_tokens=max_tokens_0)\n            #print(f\"\\nSummary chunk number {i}\")\n            #print(chunk_summary)\n        except torch.cuda.OutOfMemoryError as e:\n            print(f\"⚠️ Ошибка нехватки памяти CUDA, слишком длинный чанк: {str(e)[:100]}...\")\n            return 'ERROR'\n\n        summaries.append(chunk_summary)\n        torch.cuda.empty_cache()\n    combined_summary = \"\\n\".join(summaries)\n    \n    try:\n        final_summary = qwen(article=combined_summary, prompt=prompt_1, max_tokens=max_tokens_1)\n    except torch.cuda.OutOfMemoryError as e:\n        print(f\"⚠️ Ошибка нехватки памяти CUDA при итоговой суммаризации: {str(e)[:100]}...\")\n        return 'ERROR'\n    return final_summary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T23:32:55.578043Z","iopub.execute_input":"2026-01-09T23:32:55.57835Z","iopub.status.idle":"2026-01-09T23:32:55.584906Z","shell.execute_reply.started":"2026-01-09T23:32:55.578325Z","shell.execute_reply":"2026-01-09T23:32:55.584316Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"rouge_list = []\nbert_list = []\nldfacts_list = []\nsummaries_list = []\n\ndef to_full_text(data_dict):\n    text = ''\n    for key, value in data_dict.items(): \n        text += f\"{key}\\n\\n{value}\\n\\n\"\n    return text\n\n\nfor i in range(20):\n    print(f\"\\n=== Статья {i} ===\")\n    #извлекаем чанки, абстракт, названия разделов\n    article_dict = ast.literal_eval(df['dict_test'].iloc[i]) #словарь для i-той статьи \n    chunked_article = list(article_dict.values()) #список чанков\n    chapters_list = list(article_dict.keys()) #список глав\n    print('Список разделов')\n    display(pd.DataFrame(chapters_list))\n    abstract = df['abstract'].iloc[i] \n    article = to_full_text(article_dict) #полный текст статьи с ключами и значениями словаря\n    \n    print(f\"Токенов в статье: {len(tokenizer.encode('\\n'.join(chunked_article)))}\")\n    prompt_0 = \"You're a science editor. Briefly summarize this fragment of the scientific text in original language. Do not add information that is not in the source texts\"\n    prompt_1 = \"You're a science editor. Based on the following summaries of the parts of the article, create a single, coherent and concise summary of the entire scientific article in original language, highlighting the common goal, methods, key results and conclusion. Do not add information that is not in the source texts\"\n    \n    summary_full = summarize(chunked_article, prompt_0 = prompt_0, prompt_1 = prompt_1, max_tokens_0 = 500, max_tokens_1 = 700, text_splitter = False)\n    print(f'\\nSummary article number {i}')\n    print(summary_full)\n    summaries_list.append({\n        'article_id': i,\n        'original_text': article,\n        'abstract': abstract,\n        'summary': summary_full\n    })\n    append_summary_to_file(f\"--- Summury #{i} ---\")\n    append_summary_to_file(summary_full)\n    append_summary_to_file(\"\")\n    \n    results = rouge.compute(\n    predictions=[summary_full],\n    references=[article],\n    use_stemmer=True\n    )\n    print(\"ROUGE Metrics:\")\n\n    rouge_dict = {}\n    for key, value in results.items():\n        print(f\"{key}: {value:.4f}\")\n        rouge_dict[key] = value\n    rouge_list.append(rouge_dict)\n\n    _, _, F1 = scorer.score([summary_full], [abstract])\n    bert_f1 = F1.item()\n    print(f\"\\nBERTScore: F1 = {bert_f1:.4f}\")\n    bert_list.append(bert_f1)\n\n    ldfacts_sum = ldfacts_scorer.score_src_hyp_long([article], [summary_full])\n    ldfacts_abs = ldfacts_scorer.score_src_hyp_long([article], [abstract])\n    print(f\"LongDocFACTScore for sum: {ldfacts_sum[0]}\")\n    print(f\"LongDocFACTScore for abstract: {ldfacts_abs[0]}\")\n    ldfacts_list.append({\n        'for_summary': ldfacts_sum[0],\n        'for_abstract': ldfacts_abs[0]\n    })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T23:33:28.070907Z","iopub.execute_input":"2026-01-09T23:33:28.071224Z","iopub.status.idle":"2026-01-10T01:39:46.688133Z","shell.execute_reply.started":"2026-01-09T23:33:28.071197Z","shell.execute_reply":"2026-01-10T01:39:46.687052Z"}},"outputs":[{"name":"stdout","text":"\n=== Статья 0 ===\nСписок разделов\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                   0\n0           I. INTRODUCTION AND PROBLEM FORMULATIONS\n1                                              DRAFT\n2                               II. FUNDAMENTAL TOOL\n3  IV. FREQUENCY-DEPENDENT BALANCED TRUNCATION OV...\n4  Theorem 4.4 (Interval-type Frequency-dependent...\n5                                                , n\n6                                        V. EXAMPLES\n7                        Indexes computation formula\n8                         Berlin/Heidelberg, Germany","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I. INTRODUCTION AND PROBLEM FORMULATIONS</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>DRAFT</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>II. FUNDAMENTAL TOOL</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>IV. FREQUENCY-DEPENDENT BALANCED TRUNCATION OV...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Theorem 4.4 (Interval-type Frequency-dependent...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>, n</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>V. EXAMPLES</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Indexes computation formula</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Berlin/Heidelberg, Germany</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Токенов в статье: 6903\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9779430d5c14ad7b7183dc8a09e2397"}},"metadata":{}},{"name":"stdout","text":"\nSummary article number 0\nThe article addresses model order reduction (MOR) for linear time-invariant continuous-time systems with large orders, where computational and storage costs hinder simulation, optimization, and design. The primary goal is to construct a reduced-order model of order 3 that accurately approximates the system's dynamic behavior near ω = 0, particularly within a known finite frequency interval. Standard balanced truncation (FIBT) is inadequate for this finite-frequency objective, as it provides entire-frequency error bounds and does not optimize in-band performance. To improve finite-frequency approximation, balancing-related methods such as singular perturbation approximation (SPA), frequency-weighted balanced truncation (FWBT), and frequency-limited Grammians balanced truncation (FGBT) are considered. However, these methods either require iterative design, increase model order, or suffer from non-positive semi-definite Gramians and lack of error bounds.  \n\nThe study introduces an interval-type frequency-dependent balanced truncation (FDBT) method, which extends standard balanced truncation to finite frequency intervals. This method defines interval-type frequency-dependent controllability and observability Gramians, constructs a balanced realization via coordinate transformation, and derives both interval-type and entire-frequency error bounds. The reduced model preserves stability and provides a frequency-dependent error bound over the specified interval [̟₁, ̟₂], with the interval-type error bound tending to zero as the interval size decreases. The method is valid for both stable and unstable systems, works in complex settings, and yields real reduced models when applied to real systems with symmetric frequency intervals.  \n\nKey results show that interval-type FDBT outperforms standard FIBT and FGBT in in-band approximation, especially for medium-sized frequency intervals, with smaller error bounds and better performance near ω = 0. Experimental validation on random stable systems and a ladder circuit demonstrates that interval-type FDBT provides superior low-frequency approximation, particularly when the operating frequency is near zero. The method is distinct from SPA and other balancing approaches, offering a new, theoretically grounded alternative with explicit error bounds tailored to finite-frequency applications.  \n\nIn conclusion, the proposed interval-type FDBT method provides a robust, stable, and performance-optimized approach for reducing high-order systems with known finite-frequency operating ranges, enabling accurate and reliable approximation of dynamic behavior in practical applications.\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nROUGE Metrics:\nrouge1: 0.1276\nrouge2: 0.0642\nrougeL: 0.0740\nrougeLsum: 0.1088\n\nBERTScore: F1 = 0.6902\nLongDocFACTScore for sum: -4.1922071530268745\nLongDocFACTScore for abstract: -5.1785284042358395\n\n=== Статья 1 ===\nСписок разделов\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                    0\n0                                        INTRODUCTION\n1   BACKGROUND: RECURRENT NEURAL NETWORK LANGUAGE ...\n2                   AUGMENTING THE CROSS-ENTROPY LOSS\n3       THEORETICALLY DRIVEN REUSE OF WORD EMBEDDINGS\n4                                        RELATED WORK\n5                                         EXPERIMENTS\n6                       MODEL AND TRAINING HIGHLIGHTS\n7   EMPIRICAL VALIDATION FOR THE THEORY OF REUSING...\n8              RESULTS ON PTB AND WIKITEXT-2 DATASETS\n9                                 QUALITATIVE RESULTS\n10                                         CONCLUSION\n11              APPENDIX A MODEL AND TRAINING DETAILS\n12        B METRIC FOR CALCULATING SUBSPACE DISTANCES\n13                                               2001","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>INTRODUCTION</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BACKGROUND: RECURRENT NEURAL NETWORK LANGUAGE ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AUGMENTING THE CROSS-ENTROPY LOSS</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>THEORETICALLY DRIVEN REUSE OF WORD EMBEDDINGS</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RELATED WORK</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>EXPERIMENTS</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>MODEL AND TRAINING HIGHLIGHTS</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>EMPIRICAL VALIDATION FOR THE THEORY OF REUSING...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RESULTS ON PTB AND WIKITEXT-2 DATASETS</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>QUALITATIVE RESULTS</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>CONCLUSION</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>APPENDIX A MODEL AND TRAINING DETAILS</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>B METRIC FOR CALCULATING SUBSPACE DISTANCES</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2001</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Токенов в статье: 5944\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5ddeaf3dd1b4dfa96280c1f670e9f10"}},"metadata":{}},{"name":"stdout","text":"\nSummary article number 1\nThe article proposes a novel loss framework for recurrent neural network language models (RNNLMs) that addresses two key limitations of conventional models: the absence of a natural metric on output classes and the treatment of inputs and outputs as isolated. The framework introduces two interlinked improvements: (1) an augmented cross-entropy loss that minimizes the Kullback-Leibler divergence between model predictions and a target distribution derived from word embedding similarities, thereby leveraging the intrinsic metric structure of language embeddings; and (2) a theoretical and empirical mechanism that ties the output projection matrix to the input embedding matrix by reusing the input embedding matrix as the output classification matrix, reducing model complexity and improving information efficiency. The method is validated on the Penn Treebank and Wikitext-2 datasets, where models incorporating both improvements outperform baseline RNNLMs, with the combined approach (REAL) achieving superior performance, especially in large models where embedding reuse yields significant gains in parameter efficiency and accuracy. The results demonstrate that the proposed framework enhances prediction quality by assigning higher probabilities to semantically similar words and reducing reliance on the <unk> token, while also enabling a reduction in trainable parameters through shared representations. The findings confirm that the loss augmentation improves learning by providing more informative supervision, and that explicit reuse of input embeddings is both theoretically justified and empirically effective, offering a scalable and efficient improvement for language modeling and related NLP tasks.\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nROUGE Metrics:\nrouge1: 0.0863\nrouge2: 0.0356\nrougeL: 0.0539\nrougeLsum: 0.0717\n\nBERTScore: F1 = 0.7024\nLongDocFACTScore for sum: -5.553670024871826\nLongDocFACTScore for abstract: -4.481736040115356\n\n=== Статья 2 ===\nСписок разделов\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                  0\n0                                      INTRODUCTION\n1                                      OUR APPROACH\n2   MULTI-VIEW LEARNING OF ACOUSTIC WORD EMBEDDINGS\n3             RECURRENT NEURAL NETWORK ARCHITECTURE\n4                                      RELATED WORK\n5                           EXPERIMENTS AND RESULTS\n6                                              DATA\n7           MODEL DETAILS AND HYPERPARAMETER TUNING\n8                   EFFECTS OF DIFFERENT OBJECTIVES\n9                                         Objective\n10                                           Method\n11                            WORD SIMILARITY TASKS\n12              VISUALIZATION OF LEARNED EMBEDDINGS\n13                                       CONCLUSION\n14                                  ACKNOWLEDGMENTS\n15     Published as a conference paper at ICLR 2017\n16                            A ADDITIONAL ANALYSIS\n17                                     Architecture\n18                                       2014. 2014","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>INTRODUCTION</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>OUR APPROACH</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MULTI-VIEW LEARNING OF ACOUSTIC WORD EMBEDDINGS</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RECURRENT NEURAL NETWORK ARCHITECTURE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RELATED WORK</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>EXPERIMENTS AND RESULTS</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>DATA</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>MODEL DETAILS AND HYPERPARAMETER TUNING</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>EFFECTS OF DIFFERENT OBJECTIVES</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Objective</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Method</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>WORD SIMILARITY TASKS</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>VISUALIZATION OF LEARNED EMBEDDINGS</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>CONCLUSION</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>ACKNOWLEDGMENTS</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Published as a conference paper at ICLR 2017</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>A ADDITIONAL ANALYSIS</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Architecture</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2014. 2014</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Токенов в статье: 6253\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4086373a941348fa9b1eae4393eccf39"}},"metadata":{}},{"name":"stdout","text":"\nSummary article number 2\nThis work proposes a multi-view approach to learn acoustic word embeddings that capture the phonetic characteristics of words by jointly modeling acoustic and orthographic sequences. Unlike prior single-view methods that rely on classification or non-learned distance metrics like dynamic time warping, the proposed method uses bidirectional LSTM networks to learn fixed-dimensional embeddings from both acoustic features (e.g., MFCCs) and character sequences. A multi-view contrastive loss is introduced, enforcing that embeddings of matched acoustic-orthographic pairs are closer than those of mismatched pairs, enabling direct comparison between spoken and written forms. The method includes both fixed-margin and cost-sensitive contrastive objectives, with the latter adjusting the margin based on Levenshtein edit distance to better align embedding distances with orthographic similarity.  \n\nExperiments on the Switchboard corpus show that the multi-view approach significantly outperforms prior methods: the best model achieves 0.806 average precision (AP) in acoustic word discrimination and 0.892 in cross-view discrimination, surpassing DTW-based and autoencoder-based baselines. The cost-sensitive objective improves alignment with edit distances in word similarity tasks, though performance remains limited due to insufficient training data with similar word pairs. Despite this, both acoustic and orthographic embeddings show strong clustering behavior in t-SNE visualizations, with suffix-based words forming coherent groups. The study concludes that joint learning of acoustic and orthographic views enables more effective, discriminative, and transferable word embeddings, offering a superior alternative to sequence-based methods like DTW.\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nROUGE Metrics:\nrouge1: 0.0856\nrouge2: 0.0391\nrougeL: 0.0515\nrougeLsum: 0.0743\n\nBERTScore: F1 = 0.7206\nLongDocFACTScore for sum: -4.167446494102478\nLongDocFACTScore for abstract: -4.3108125030994415\n\n=== Статья 3 ===\nСписок разделов\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                    0\n0                                        Introduction\n1                         Background and related work\n2                                  Gaussian processes\n3                            Spectral mixture kernels\n4                                        Related work\n5                                          Motivation\n6   Spectral mixture kernel with dependency structure\n7     Modeling dependency structure using convolution\n8   Time and phase characterized Gaussian spectral...\n9       Time-and phase modulated dependency structure\n10  Spectral mixture with TP modulated dependency ...\n11             Interpretation of dependency structure\n12    Comparisons between the SMD and related kernels\n13  Structure adaptation for the spectral mixture ...\n14  Bootstrap-based hyperparameter initialization ...\n15  Algorithm 2: Bootstrap-based hyperparameter in...\n16  Compressed spectral mixture with dependency st...\n17       Sparse dependency structure and its behavior\n18                                        Experiments\n19                                   Model assessment\n20  Long range interpolation of monthly river flow...\n21  Scalable SMD on large scale multidimensional data\n22                                         Conclusion\n23                                     Acknowledgment\n24                                         Discussion\n25                                     Academic press","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Introduction</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Background and related work</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Gaussian processes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Spectral mixture kernels</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Related work</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Motivation</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Spectral mixture kernel with dependency structure</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Modeling dependency structure using convolution</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Time and phase characterized Gaussian spectral...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Time-and phase modulated dependency structure</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Spectral mixture with TP modulated dependency ...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Interpretation of dependency structure</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Comparisons between the SMD and related kernels</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Structure adaptation for the spectral mixture ...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Bootstrap-based hyperparameter initialization ...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Algorithm 2: Bootstrap-based hyperparameter in...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Compressed spectral mixture with dependency st...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Sparse dependency structure and its behavior</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Experiments</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Model assessment</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Long range interpolation of monthly river flow...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Scalable SMD on large scale multidimensional data</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Conclusion</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Acknowledgment</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Discussion</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Academic press</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Токенов в статье: 8151\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/26 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fea854a18e34d1eb00d4287a3a074a0"}},"metadata":{}},{"name":"stdout","text":"\nSummary article number 3\nThe article proposes a novel spectral mixture kernel with dependency structure (SMD) that extends the classical spectral mixture (SM) kernel by explicitly modeling inter-component dependencies through a generalized cross covariance derived from Bienaymé’s identity. Unlike existing SM variants that assume independence among components, the SMD kernel captures cross-covariances between Gaussian process components using a complex-valued Gaussian mixture model with time and phase delays, enabling the modeling of temporal and phase-dependent interactions. The kernel’s spectral density is parameterized via a complex-valued Fourier transform, incorporating time and phase delays to represent realistic signal dynamics. The resulting kernel is positive definite and interpretable, with its spectral properties providing insight into dependency structures. To address challenges in hyperparameter initialization, component selection, and interpretability, the authors introduce a structure adaptation (SA) algorithm that uses bootstrap-based initialization, component pruning based on component weights, and sparsification of weak dependency structures. This algorithm reduces the hyperparameter space, improves learning efficiency, and preserves meaningful dependencies. The SMD kernel generalizes the original SM kernel, reducing to it when no inter-component dependencies are considered. The method is evaluated on synthetic and real-world datasets—including a monthly river flow and yearly sunspot time series—showing that SMD outperforms SM and other baselines in interpolation, extrapolation, and prediction accuracy, with tighter confidence intervals and better handling of missing data. The model also demonstrates scalability on multidimensional data via variational inference, with significant compression (CR > 30%) and sparse dependency structures (SR > 89%). The key contributions are: (1) a formal representation of dependency structure via cross covariance; (2) a complex-valued GMM with time and phase delays for spectral modeling; (3) an interpretable and expressive SMD kernel; (4) an effective and interpretable SA algorithm; and (5) empirical validation of interpolation, extrapolation, scalability, and dependency sparsity. The study concludes that the SMD kernel enables more accurate and interpretable function approximation by explicitly modeling latent dependencies between components, particularly in time-delayed or physically coupled systems.\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nROUGE Metrics:\nrouge1: 0.0957\nrouge2: 0.0447\nrougeL: 0.0547\nrougeLsum: 0.0794\n\nBERTScore: F1 = 0.7107\nLongDocFACTScore for sum: -4.881683869795366\nLongDocFACTScore for abstract: -4.574126243591309\n\n=== Статья 4 ===\nСписок разделов\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                    0\n0                                        Introduction\n1            Macaulay linear systems and their tQLScn\n2                             Macaulay linear systems\n3   Lower bound on the truncated QLS condition num...\n4                    Comparison to brute-force search\n5   The Boolean Macaulay linear system and its tQLScn\n6                  The Boolean Macaulay matrix over C\n7   Definition 5.1. The Boolean Macaulay matrix B ...\n8                         Lower bound on the tQLScn κ\n9                     Details comparing running times\n10                                      The algorithm\n11                                         Discussion\n12                  B Bounds on binomial coefficients\n13                                   Acknowledgements\n14         A Simple proof of the unique solution case\n15                                                 11","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Introduction</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Macaulay linear systems and their tQLScn</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Macaulay linear systems</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lower bound on the truncated QLS condition num...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Comparison to brute-force search</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>The Boolean Macaulay linear system and its tQLScn</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>The Boolean Macaulay matrix over C</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Definition 5.1. The Boolean Macaulay matrix B ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Lower bound on the tQLScn κ</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Details comparing running times</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>The algorithm</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Discussion</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>B Bounds on binomial coefficients</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Acknowledgements</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>A Simple proof of the unique solution case</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Токенов в статье: 13917\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fe7092894f24ebb81d9914919503c26"}},"metadata":{}},{"name":"stdout","text":"\nSummary article number 4\nThe article studies the problem of solving systems of multivariate polynomial equations over \\( \\mathbb{F}_2 \\), which is known to be NP-complete. The approach involves linearizing the system via the Macaulay matrix, which encodes the polynomials and their monomial products. The authors analyze the application of the HHL quantum linear system (QLS) algorithm to solve this linear system, aiming to avoid explicit Gröbner basis computation. They demonstrate that the standard requirements for QLS—efficient preparation of the input state, solution extraction, and sparse matrix access—are satisfied. However, they prove an exponential lower bound on the condition number \\( \\kappa \\) of the Macaulay matrix, specifically \\( \\Omega(n^h) \\) for a unique solution with Hamming weight \\( h \\), and show that this bound holds even under max degree. This implies that the HHL-based quantum algorithm requires exponential time in the worst case, with complexity \\( \\Omega((3n)^{h/2}) \\).\n\nThe authors introduce a refined \"Boolean Macaulay matrix\" over \\( \\mathbb{C} \\), derived via Gaussian elimination, which is smaller and preserves the solution set. This leads to a lower bound of \\( \\Omega(2^{h/2}) \\) on the condition number, improving upon the previous bound. When the Hamming weight \\( h = \\Theta(\\log n) \\), this bound is polynomial, leaving open the possibility of superpolynomial quantum speedup. They also define a truncated QLS condition number \\( \\kappa_b(\\mathbf{M}) \\), which is lower-bounded and rules out improvements via truncated algorithms. For systems with multiple solutions of equal Hamming weight, the condition number can be reduced by at most a factor of \\( \\sqrt{t} \\), where \\( t \\) is the number of solutions.\n\nThe authors compare the quantum approach to classical methods: brute-force search over all \\( n \\)-bit strings of weight \\( h \\) requires \\( O(n^h) \\) time, while Grover search achieves \\( O(\\sqrt{n^h}) \\). When the solution weight is unknown, classical iteration requires \\( O(\\sqrt{h} n^h) \\) assignments. In contrast, the quantum algorithm has complexity \\( O(\\kappa) \\), and the lower bound shows that it is outperformed by Grover when \\( d + h \\geq n \\). The Boolean Macaulay matrix approach enables efficient solution extraction via a modified algorithm with only \\( O(\\log n) \\) iterations, reducing the total cost to \\( O(n \\log n) \\), and allows for a potential superpolynomial speedup when \\( h = \\Theta(\\log n) \\).\n\nThe paper provides a self-contained proof of correctness using affine hashing and the Valiant-Vazirani reduction, reducing multi-solution systems to unique ones. It also shows that the solution vector is a 0/1 vector, enabling direct measurement and classical interpretation. The results establish that the quantum algorithm does not offer a speedup over classical brute-force search in general, due to the exponential lower bound on the condition number, and that the problem remains intractable for cryptographic applications where solutions are rare. The work also highlights the limitations of truncated and preconditioned QLS variants, and shows that the Boolean Macaulay system cannot be dequantized classically\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nROUGE Metrics:\nrouge1: 0.0857\nrouge2: 0.0504\nrougeL: 0.0535\nrougeLsum: 0.0763\n\nBERTScore: F1 = 0.6749\nLongDocFACTScore for sum: -3.8184351544631157\nLongDocFACTScore for abstract: -4.2445260882377625\n\n=== Статья 5 ===\nСписок разделов\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                    0\n0                                        Introduction\n1                               The SIMMC 2.0 Dataset\n2   Multi-Modal Coreference Resolution and Disambi...\n3                                           Baselines\n4                                              Models\n5                                   Sub-Task #1 Model\n6                                   Sub-Task #2 Model\n7                        Multi-Modal model definition\n8                             Sub-Task #1 Experiments\n9                             Sub-Task #2 Experiments\n10                                    Model Ablations\n11                                        Coreference\n12                                      Task Analysis\n13                             Ambiguous coreferences\n14                                         Conclusion\n15                                   Acknowledgements\n16  the 2020 Conference on Empirical Methods in Na...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Introduction</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The SIMMC 2.0 Dataset</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Multi-Modal Coreference Resolution and Disambi...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Baselines</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Models</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Sub-Task #1 Model</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Sub-Task #2 Model</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Multi-Modal model definition</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Sub-Task #1 Experiments</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Sub-Task #2 Experiments</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Model Ablations</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Coreference</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Task Analysis</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Ambiguous coreferences</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Conclusion</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Acknowledgements</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>the 2020 Conference on Empirical Methods in Na...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Токенов в статье: 7446\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/17 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1b48df1f4024ab1aa89e39df494fde3"}},"metadata":{}},{"name":"stdout","text":"\nSummary article number 5\nThis paper presents a submission to the SIMMC 2.0 challenge, aiming to develop a conversational agent acting as a shopping assistant that operates within immersive scene contexts by leveraging only accessible metadata. The core goal is to enable effective dialogue in real-world tasks through accurate disambiguation and coreference resolution, both of which depend on multi-modal context (language and visual scene). The authors propose two models: a disambiguation predictor based on TOD-BERT and a coreference resolver using LXMERT with object descriptions derived from visual features. Both models are evaluated on sub-tasks involving ambiguity detection and object reference resolution.  \n\nKey results show that disambiguation can be predicted with over 88% accuracy using only linguistic context—without dialogue history or visual input—suggesting that language models exploit syntactic patterns (e.g., prepositions, wh-questions, sentence length) and data biases. In coreference resolution, a LXMERT-based model achieves 60.83% object F1 using dialogue context and object descriptions, with visual features playing a supporting but not dominant role. Ablation studies reveal that language is the most critical component, while object positional IDs and visual features (especially RoI features) contribute modestly. Removing previously mentioned objects reduces performance by 11.9%, highlighting their importance. The model learns object representations from object IDs alone, even when randomly assigned, and performance improves when global tokens based on prefab model IDs are introduced.  \n\nThe study concludes that multi-modality is not strictly necessary for high performance in these sub-tasks, as strong unimodal models achieve state-of-the-art results. However, the challenge remains in distinguishing objects in cluttered scenes, where visual discrimination is limited. The findings suggest that coreference resolution benefits more from structured textual descriptions of objects than from raw visual features, and that object representations can be effectively learned from metadata alone. The work underscores the need for systematic methods to disentangle object representations for better disambiguation in complex visual scenes.\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nROUGE Metrics:\nrouge1: 0.0964\nrouge2: 0.0432\nrougeL: 0.0566\nrougeLsum: 0.0794\n\nBERTScore: F1 = 0.6883\nLongDocFACTScore for sum: -4.232152755443867\nLongDocFACTScore for abstract: -5.499554531914847\n\n=== Статья 6 ===\nСписок разделов\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                 0\n0                                     Introduction\n1                                     Related Work\n2                                    Contributions\n3                                      Methodology\n4                                       Background\n5                                             UNet\n6                             Spatial Transformers\n7                 Graph Neural Networks and SCGNet\n8                          Proposed Method: MICDIR\n9                                       Hypotheses\n10                                 Method Overview\n11  Architecture of MSCGUNet -the proposed network\n12                              Training Procedure\n13                                       Baselines\n14                Non-Deep Learning Baseline: ANTs\n15             Naive Baseline: Direct Optimisation\n16                    Implementation and Training.\n17                   Deep Learning Baseline: ADMIR\n18              Deep Learning Baseline: Voxelmorph\n19                                         Dataset\n20                              Data Preprocessing\n21                                      Evaluation\n22                          Results and Discussion\n23                             Direct Optimisation\n24                             Comparative Results\n25                         Intramodel Registration\n26                         Intermodal Registration\n27                        Ablation Study of MICDIR\n28                                 Acknowledgement\n29                                              12","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Introduction</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Related Work</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Contributions</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Methodology</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Background</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>UNet</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Spatial Transformers</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Graph Neural Networks and SCGNet</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Proposed Method: MICDIR</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Hypotheses</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Method Overview</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Architecture of MSCGUNet -the proposed network</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Training Procedure</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Baselines</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Non-Deep Learning Baseline: ANTs</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Naive Baseline: Direct Optimisation</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Implementation and Training.</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Deep Learning Baseline: ADMIR</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Deep Learning Baseline: Voxelmorph</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Dataset</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Data Preprocessing</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Evaluation</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Results and Discussion</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Direct Optimisation</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Comparative Results</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Intramodel Registration</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Intermodal Registration</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Ablation Study of MICDIR</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Acknowledgement</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Токенов в статье: 9621\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0233a3488ce74efe87167b42443ef491"}},"metadata":{}},{"name":"stdout","text":"\nSummary article number 6\nThe proposed method, MICDIR (Multi-scale Inverse-Consistent Deformable Image Registration), presents an unsupervised deep learning framework for both intramodal and intermodal brain MRI registration. It leverages a multi-scale UNet architecture with self-constructing graph latent network (SCGNet) to capture global structural dependencies and handle deformations of varying scales, while enforcing inverse consistency via cycle consistency loss to ensure symmetric and physically plausible transformations. The model integrates semantic information through SCGNet, employs multi-scale supervision to improve training stability and fine-detail preservation, and ensures deformation consistency in both forward and inverse directions. Evaluated on the IXI dataset using T1w and T2w MRI pairs, MICDIR outperforms non-deep learning (ANTS SyN) and three deep learning baselines (ICNet, Voxelmorph, ADMIR) in both intramodal and intermodal registration tasks, achieving statistically significant improvements in Dice coefficient, Kullback-Leibler distance, and structural similarity metrics. Ablation studies confirm the contributions of multi-scale supervision, inverse consistency, and SCGNet to registration accuracy and generalisation. The method demonstrates superior performance, robustness, and inverse consistency, with enhanced generalisation across preprocessing pipelines, making it a promising solution for accurate and reliable deformable image registration in clinical and research settings.\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nROUGE Metrics:\nrouge1: 0.0477\nrouge2: 0.0257\nrougeL: 0.0313\nrougeLsum: 0.0424\n\nBERTScore: F1 = 0.6623\nLongDocFACTScore for sum: -4.538436532020569\nLongDocFACTScore for abstract: -4.316442532972856\n\n=== Статья 7 ===\nСписок разделов\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                    0\n0                                        Introduction\n1   Guidelines on techniques and tricks for effici...\n2                        Transformers: Nuts and Bolts\n3                        The Transformer Architecture\n4                            Self-Attention Operation\n5                 The Intuition Behind Self-Attention\n6   Linearly Weighting Input Using Query, Key, and...\n7                           Multi-Head Self-Attention\n8   Step 1 -Generation of Multiple Sets of Distinc...\n9   Step-2 -Scaled Dot Product Operations in Parallel\n10  Step-3 -Concatenating and Linearly Combining O...\n11  Building Transformers Using Encoders and Decoders\n12                                  The Encoder Block\n13                                  The Decoder Block\n14                          Masking in Self-Attention\n15                     Stacking Encoders and Decoders\n16                                         The Output\n17                           Positional Encoding (PE)\n18                                      Sinusoidal PE\n19  Relationship of the Sinusoidal PE with Binary ...\n20            Positional Encoding and Rotation Matrix\n21  Combining Positional Encoding with Word Embedd...\n22  Road Map of Transformers for Time-Series Analysis\n23  Avenues of Improvement for Time-Series Transfo...\n24                                 Data Preprocessing\n25                          Positional Encoding (PEs)\n26                                   Gating Operation\n27                                          Attention\n28                                        Convolution\n29                    Interpretability/Explainability\n30                                Dense Interpolation\n31                                      BERT-Inspired\n32                                       GAN-Inspired\n33                                  Time-Series Tasks\n34                          The Informer Architecture\n35                 LogSparse Transformer Architecture\n36                  Simply Attend and Diagnose (SAnD)\n37                                Traffic Transformer\n38  Self-Attention for Raw Optical Satellite Time-...\n39  Deep Transformer Models for Time-Series Foreca...\n40  Best Practices for Training Time-Series Transf...\n41                              Training Transformers\n42    Implementing Transformers in Popular Frameworks\n43                                       Hugging Face\n44  Improvements in the Transformer Architecture f...\n45                                   Large Model Size\n46                       Training with Small Datasets\n47                       Other Strategies to Consider\n48                       Conclusion and Future Trends\n49                                    Acknowledgement\n50                        Data Availability Statement\n51  Funding and/or Conflicts of interests/Competin...\n52                                               2017","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Introduction</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Guidelines on techniques and tricks for effici...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Transformers: Nuts and Bolts</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The Transformer Architecture</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Self-Attention Operation</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>The Intuition Behind Self-Attention</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Linearly Weighting Input Using Query, Key, and...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Multi-Head Self-Attention</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Step 1 -Generation of Multiple Sets of Distinc...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Step-2 -Scaled Dot Product Operations in Parallel</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Step-3 -Concatenating and Linearly Combining O...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Building Transformers Using Encoders and Decoders</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>The Encoder Block</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>The Decoder Block</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Masking in Self-Attention</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Stacking Encoders and Decoders</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>The Output</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Positional Encoding (PE)</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Sinusoidal PE</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Relationship of the Sinusoidal PE with Binary ...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Positional Encoding and Rotation Matrix</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Combining Positional Encoding with Word Embedd...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Road Map of Transformers for Time-Series Analysis</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Avenues of Improvement for Time-Series Transfo...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Data Preprocessing</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Positional Encoding (PEs)</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Gating Operation</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Attention</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Convolution</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Interpretability/Explainability</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Dense Interpolation</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>BERT-Inspired</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>GAN-Inspired</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Time-Series Tasks</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>The Informer Architecture</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>LogSparse Transformer Architecture</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Simply Attend and Diagnose (SAnD)</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Traffic Transformer</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Self-Attention for Raw Optical Satellite Time-...</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>Deep Transformer Models for Time-Series Foreca...</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Best Practices for Training Time-Series Transf...</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>Training Transformers</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>Implementing Transformers in Popular Frameworks</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>Hugging Face</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>Improvements in the Transformer Architecture f...</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>Large Model Size</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>Training with Small Datasets</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>Other Strategies to Consider</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>Conclusion and Future Trends</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>Acknowledgement</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>Data Availability Statement</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>Funding and/or Conflicts of interests/Competin...</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>2017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Токенов в статье: 11993\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/53 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4c1441aea93475f9374516b5d5c3ff5"}},"metadata":{}},{"name":"stdout","text":"⚠️ Ошибка нехватки памяти CUDA при итоговой суммаризации: CUDA out of memory. Tried to allocate 5.54 GiB. GPU 0 has a total capacity of 14.74 GiB of which 4.5...\n\nSummary article number 7\nERROR\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nROUGE Metrics:\nrouge1: 0.0002\nrouge2: 0.0000\nrougeL: 0.0002\nrougeLsum: 0.0002\n\nBERTScore: F1 = 0.5557\nLongDocFACTScore for sum: -13.103875160217285\nLongDocFACTScore for abstract: -4.566188255945842\n\n=== Статья 8 ===\nСписок разделов\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                             0\n0                 Fully Homomorphic Encryption\n1                         The BGV Cryptosystem\n2                 Basic Homomorphic Operations\n3             Auxiliary Homomorphic Operations\n4                                Bootstrapping\n5           Data Representation and Algorithms\n6                        Residue Number System\n7                   Number-Theoretic Transform\n8    Implemented Algorithms and Parameter Sets\n9                     Supported Parameter Sets\n10                         Algorithmic Details\n11                  NTT-Friendly Bootstrapping\n12      Algorithm 1 NTT-friendly bootstrapping\n13                               System Design\n14                BASALISC Processing Elements\n15               Number-Theoretic Transform PE\n16                      Conflict-Free Schedule\n17                      Twiddle Factor Factory\n18                              Permutation PE\n19                      Multiply-Accumulate PE\n20  Modular Multiplier Arithmetic Optimization\n21                                 Artemidorus\n22                                 Simba-micro\n23                      Evaluation of BASALISC\n24                      Physical Realizability\n25     Logic Emulation and Formal Verification\n26            Benchmark Performance Simulation\n27                                Related Work\n28                       Fayetteville, AR, USA","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Fully Homomorphic Encryption</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The BGV Cryptosystem</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Basic Homomorphic Operations</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Auxiliary Homomorphic Operations</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Bootstrapping</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Data Representation and Algorithms</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Residue Number System</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Number-Theoretic Transform</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Implemented Algorithms and Parameter Sets</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Supported Parameter Sets</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Algorithmic Details</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>NTT-Friendly Bootstrapping</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Algorithm 1 NTT-friendly bootstrapping</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>System Design</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>BASALISC Processing Elements</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Number-Theoretic Transform PE</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Conflict-Free Schedule</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Twiddle Factor Factory</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Permutation PE</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Multiply-Accumulate PE</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Modular Multiplier Arithmetic Optimization</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Artemidorus</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Simba-micro</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Evaluation of BASALISC</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Physical Realizability</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Logic Emulation and Formal Verification</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Benchmark Performance Simulation</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Related Work</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Fayetteville, AR, USA</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Токенов в статье: 12333\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52da4513698c4a3290a0f7d7bfc6b1d7"}},"metadata":{}},{"name":"stdout","text":"⚠️ Ошибка нехватки памяти CUDA при итоговой суммаризации: CUDA out of memory. Tried to allocate 5.22 GiB. GPU 0 has a total capacity of 14.74 GiB of which 4.9...\n\nSummary article number 8\nERROR\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nROUGE Metrics:\nrouge1: 0.0002\nrouge2: 0.0000\nrougeL: 0.0002\nrougeLsum: 0.0002\n\nBERTScore: F1 = 0.5086\nLongDocFACTScore for sum: -10.333335876464844\nLongDocFACTScore for abstract: -5.4921878178914385\n\n=== Статья 9 ===\nСписок разделов\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                        0\n0                               , 20% ons\n1                               C. Comple\n2                  D. Our Final Selection\n3       III. Selected Ternary Full Adders\n4                                    H+ c\n5                      D. Design in [103]\n6                       E. Design in [58]\n7                       G. Design in [60]\n8                            H. Design in\n9   IV. Simulation Results and Comparison\n10        V. Conclusions and Future Works\n11                          Naples, Italy","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>, 20% ons</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>C. Comple</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>D. Our Final Selection</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>III. Selected Ternary Full Adders</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>H+ c</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>D. Design in [103]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>E. Design in [58]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>G. Design in [60]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>H. Design in</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>IV. Simulation Results and Comparison</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>V. Conclusions and Future Works</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Naples, Italy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Токенов в статье: 7209\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bcedb1c9978440586f35cb393c0ae88"}},"metadata":{}},{"name":"stdout","text":"\nSummary article number 9\nThe article presents a comprehensive taxonomic classification and performance analysis of ternary logic circuits, focusing on Ternary Full Adders (TFAs). The primary goal is to identify, evaluate, and simplify existing TFA designs to improve their power efficiency, speed, and transistor count. The review identifies 13 ternary logic styles, most derived from binary logic, including CMOS, CML, dynamic, and decoder-based approaches, with static logic dominating (90.4%) and dynamic and CML designs being rare due to power and complexity issues. Input decoding methods are categorized, with multi-threshold transistors being the most prevalent. A comprehensive set of 84 initial designs is pruned to 11 representative papers based on criteria such as full transistor implementation, single-V DD operation, unbalanced ternary logic, and power efficiency, eliminating designs with multi-V DD, balanced ternary, dynamic logic, or poor power characteristics. Key simplifications are introduced: partial TFAs are developed where the output carry voltage is set to V_DD, eliminating internal voltage division and reducing power dissipation; transistors dependent on the input signal c='2' are removed since c never takes that value; ternary logic gates are replaced with binary gates to reduce transistor count and improve performance. These modifications result in significant improvements: up to 70.2% lower PDP, 26.9% reduced power consumption, 24.8% faster operation, and 22.8% better power efficiency. The study demonstrates that partial TFAs with full-swing output carry and simplified gate structures outperform complete TFAs in power and performance. Despite these advances, the paper concludes that further research is needed to develop faster, lower-power, and more compact ternary adders, with multi-V DD designs suggested as a promising future direction. All simulations are performed using HSPICE with a 32nm CNFET library at 0.9V and 1GHz, with input patterns and loads standardized, and key observations include the inefficiency of voltage division, the performance benefits of cascaded THAs, and the superiority of binary gate replacement in ternary circuits. No single logic family is declared superior due to their distinct trade-offs.\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nROUGE Metrics:\nrouge1: 0.1162\nrouge2: 0.0477\nrougeL: 0.0596\nrougeLsum: 0.0852\n\nBERTScore: F1 = 0.6729\nLongDocFACTScore for sum: -5.1499370878393\nLongDocFACTScore for abstract: -5.229717884744916\n\n=== Статья 10 ===\nСписок разделов\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                    0\n0                                          III. MODEL\n1                                       A. Components\n2     B. Trade-offs of discrete audio representations\n3   C. Hierarchical modeling of semantic and acous...\n4                                        D. Inference\n5                                     IV. EXPERIMENTS\n6                                         A. Datasets\n7          B. Model selection, training and inference\n8   C. Information represented by the semantic tokens\n9   D. Information represented by the acoustic tokens\n10     E. Probing the linguistic knowledge of AudioLM\n11               F. Generating coherent continuations\n12                           G. Subjective evaluation\n13                    H. Detecting synthesized speech\n14                              I. Piano continuation\n15                                      V. CONCLUSION\n16                                 VI. BROADER IMPACT\n17                              VII. ACKNOWLEDGEMENTS\n18                                               2016","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>III. MODEL</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A. Components</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>B. Trade-offs of discrete audio representations</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>C. Hierarchical modeling of semantic and acous...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>D. Inference</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>IV. EXPERIMENTS</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>A. Datasets</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>B. Model selection, training and inference</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>C. Information represented by the semantic tokens</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>D. Information represented by the acoustic tokens</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>E. Probing the linguistic knowledge of AudioLM</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>F. Generating coherent continuations</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>G. Subjective evaluation</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>H. Detecting synthesized speech</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>I. Piano continuation</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>V. CONCLUSION</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>VI. BROADER IMPACT</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>VII. ACKNOWLEDGEMENTS</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2016</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Токенов в статье: 7913\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1dc8c4f77634aa3859d432af9c12519"}},"metadata":{}},{"name":"stdout","text":"\nSummary article number 10\nAudioLM is a framework for high-fidelity audio generation that achieves both long-term structural coherence and high audio quality through a hierarchical, multi-stage autoregressive model using a hybrid tokenization scheme. The framework employs acoustic tokens—derived from a SoundStream neural codec—to preserve fine-grained acoustic details and speaker identity, and semantic tokens—extracted from w2v-BERT and clustered via k-means—to capture linguistic content and long-term temporal structure. These are processed in three cascaded stages: first, semantic tokens are generated autoregressively; second, coarse acoustic tokens are predicted conditionally on semantic tokens to preserve speaker identity and recording conditions; third, fine acoustic tokens are generated to refine audio quality and remove compression artifacts. The hierarchical design enables efficient modeling of long sequences while maintaining fidelity. Experiments show that semantic tokens effectively capture linguistic content, as evidenced by high performance on sWUGGY and sBLIMP metrics, and that acoustic tokens preserve speaker identity and prosody, as confirmed by speaker classification and ASR evaluations. Generated speech and piano music continuations are semantically and syntactically correct, with human listeners unable to distinguish them from real audio. AudioLM also generates consistent musical structure in piano performance, outperforming baselines in subjective evaluation. A dedicated audio classifier achieves 98.6% accuracy in detecting AudioLM-generated speech, providing a safeguard against misuse. The framework demonstrates generalizability beyond speech to music generation and supports future extensions to other audio domains.\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nROUGE Metrics:\nrouge1: 0.0721\nrouge2: 0.0344\nrougeL: 0.0457\nrougeLsum: 0.0627\n\nBERTScore: F1 = 0.7065\nLongDocFACTScore for sum: -4.514788256751166\nLongDocFACTScore for abstract: -4.645268610545567\n\n=== Статья 11 ===\nСписок разделов\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                 0\n0                                  I. INTRODUCTION\n1                                   II. MOTIVATION\n2                            A. Prompt Engineering\n3                               B. Querying an LLM\n4                           C. Test Postprocessing\n5                         D. Selection and Ranking\n6                                   IV. EVALUATION\n7                                       A. Dataset\n8                                       B. Metrics\n9                                   C. Environment\n10                           V. RESEARCH QUESTIONS\n11                                A. RQ1: Efficacy\n12                              B. RQ2: Efficiency\n13                            C. RQ3: Practicality\n14                 A. RQ1. How effective is LIBRO?\n15                 B. RQ2. How efficient is LIBRO?\n16  C. RQ3. How well would LIBRO work in practice?\n17            A. Manual Analysis of LIBRO Failures\n18                 B. Code Overlap with Bug Report\n19                       VIII. THREATS TO VALIDITY\n20                              A. Test Generation\n21                               B. Code Synthesis\n22                                   X. CONCLUSION","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I. INTRODUCTION</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>II. MOTIVATION</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A. Prompt Engineering</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>B. Querying an LLM</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>C. Test Postprocessing</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>D. Selection and Ranking</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>IV. EVALUATION</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>A. Dataset</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>B. Metrics</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>C. Environment</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>V. RESEARCH QUESTIONS</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>A. RQ1: Efficacy</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>B. RQ2: Efficiency</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>C. RQ3: Practicality</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>A. RQ1. How effective is LIBRO?</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>B. RQ2. How efficient is LIBRO?</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>C. RQ3. How well would LIBRO work in practice?</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>A. Manual Analysis of LIBRO Failures</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>B. Code Overlap with Bug Report</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>VIII. THREATS TO VALIDITY</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>A. Test Generation</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>B. Code Synthesis</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>X. CONCLUSION</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Токенов в статье: 10101\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98eb24eee1a847bb996fa54981f91a4e"}},"metadata":{}},{"name":"stdout","text":"\nSummary article number 11\nThe article addresses the under-explored problem of generating test cases from bug reports, a critical yet under-researched aspect of software testing, especially in safety-critical systems. While automated test generation has been studied for decades, most prior work focuses on crash reproduction or regression testing, neglecting the need for tests derived directly from bug reports—where such tests are often absent at report time. The authors analyze 300 open-source Java projects and find that bug-report-linked test commits account for a median of 28.4% of total test suites, underscoring the practical importance of this problem. In the Defects4J benchmark, 96% of bugs lack prior bug-revealing tests, limiting automated debugging. To bridge this gap, the authors propose LIBRO, a framework that leverages Large Language Models (LLMs) to generate test candidates from natural language bug reports, processes them for executability, and ranks them to minimize developer effort.\n\nLIBRO constructs prompts using a structured Markdown format to guide the LLM in generating test methods ending with `public void test`. It employs weighted random sampling (temperature 0.7) to generate diverse test candidates, which are then post-processed to resolve missing imports via lexical matching and heuristics. The framework evaluates test candidates based on their ability to fail in the buggy version (FIB tests), with a BRT defined as a test that fails on the buggy and passes on the fixed version. LIBRO selects and ranks test candidates using three heuristics: match to bug report, output cluster size (indicating consensus), and test length (shorter tests preferred), ensuring diversity and reducing cognitive load. Empirical evaluations on Defects4J and a new real-world dataset (GHRB) show that LIBRO generates at least one reproducing test for 33.5% and 32.2% of bugs respectively, with 71.4% accuracy in identifying successful reproductions. It outperforms EvoCrash and a Copy&Paste baseline by reproducing more non-crash bugs and achieving better ranking accuracy. The framework is efficient, with average runtime under 10 minutes, and demonstrates generalization to real-world projects. Despite limitations—such as failure due to missing helper functions or external dependencies—LIBRO successfully generates meaningful tests from incomplete or no code snippets, with 81% of generated test bodies overlapping with existing snippets. The study concludes that LIBRO effectively bridges the gap between bug reports and test generation, enabling developers to quickly reproduce bugs and improve automated testing, while highlighting the need for project-specific context and improved helper function support in future work.\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nROUGE Metrics:\nrouge1: 0.0918\nrouge2: 0.0453\nrougeL: 0.0584\nrougeLsum: 0.0757\n\nBERTScore: F1 = 0.6869\nLongDocFACTScore for sum: -4.405367851257324\nLongDocFACTScore for abstract: -5.015513944625854\n\n=== Статья 12 ===\nСписок разделов\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                    0\n0                                        Introduction\n1                                            Examples\n2                                BARBARA KALTENBACHER\n3                                                   5\n4                                            Notation\n5   Structure exploiting reconstruction methods an...\n6                          Variational reconstruction\n7                            Iterative reconstruction\n8                              A frozen Newton method\n9                                              nsp(P)\n10                           Let the stopping index n\n11                                A class of examples\n12                                Reduced formulation\n13                                             (3.21)\n14                            All-at-once formulation\n15                             Some concrete examples\n16  Remark 5 Instead of time trace observations, f...\n17  Example 6 (combined diffusion and absorption i...\n18                             Conclusion and Outlook\n19                                     Acknowledgment\n20           A. Details on examples from introduction\n21                B. Proofs of some auxiliary results\n22                 C. Two further Newton type methods\n23                                             (C.13)\n24       C.1. Convergence in the setting of Section 3\n25                                             B(u)dq\n26             6) for the transient case in Example 5\n27       D.3. Nullspace condition (3.6) for Example 6\n28                                                 23","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Introduction</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Examples</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BARBARA KALTENBACHER</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Notation</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Structure exploiting reconstruction methods an...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Variational reconstruction</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Iterative reconstruction</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>A frozen Newton method</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>nsp(P)</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Let the stopping index n</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>A class of examples</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Reduced formulation</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>(3.21)</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>All-at-once formulation</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Some concrete examples</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Remark 5 Instead of time trace observations, f...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Example 6 (combined diffusion and absorption i...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Conclusion and Outlook</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Acknowledgment</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>A. Details on examples from introduction</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>B. Proofs of some auxiliary results</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>C. Two further Newton type methods</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>(C.13)</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>C.1. Convergence in the setting of Section 3</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>B(u)dq</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>6) for the transient case in Example 5</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>D.3. Nullspace condition (3.6) for Example 6</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>23</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Токенов в статье: 18119\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"429f6c3aeb5342e6aa476e8fa1f64b6a"}},"metadata":{}},{"name":"stdout","text":"⚠️ Ошибка нехватки памяти CUDA при итоговой суммаризации: CUDA out of memory. Tried to allocate 8.84 GiB. GPU 0 has a total capacity of 14.74 GiB of which 1.0...\n\nSummary article number 12\nERROR\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nТекст добавлен в файл: /kaggle/working/all_summaries.txt\nROUGE Metrics:\nrouge1: 0.0002\nrouge2: 0.0000\nrougeL: 0.0002\nrougeLsum: 0.0002\n\nBERTScore: F1 = 0.5329\nLongDocFACTScore for sum: -13.511157035827637\nLongDocFACTScore for abstract: -4.684328715006511\n\n=== Статья 13 ===\nСписок разделов\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                  0\n0                                      Introduction\n1                                  Output Automaton\n2                                     Preliminaries\n3                  Trajectories and Hybrid automata\n4                               Definition 2 (Run).\n5                           Linear Multistep Method\n6                        Dynamic Time Warping (DTW)\n7        HA Learning from Input-Output Trajectories\n8                       Identification of Locations\n9                  Segmentation of the Trajectories\n10                                               6:\n11                    Identification of Transitions\n12  Impact of Parameter Selection on Model Accuracy\n13                                      Experiments\n14                            Benchmark Description\n15                           Results and Discussion\n16                    Comparison with other methods\n17                                       Conclusion\n18              A.2 Additional experimental results\n19                                              138","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Introduction</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Output Automaton</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Preliminaries</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Trajectories and Hybrid automata</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Definition 2 (Run).</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Linear Multistep Method</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Dynamic Time Warping (DTW)</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>HA Learning from Input-Output Trajectories</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Identification of Locations</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Segmentation of the Trajectories</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>6:</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Identification of Transitions</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Impact of Parameter Selection on Model Accuracy</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Experiments</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Benchmark Description</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Results and Discussion</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Comparison with other methods</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Conclusion</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>A.2 Additional experimental results</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>138</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Токенов в статье: 10044\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dcd2774f0c6415e85b710bc8c943196"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1264727838.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprompt_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"You're a science editor. Based on the following summaries of the parts of the article, create a single, coherent and concise summary of the entire scientific article in original language, highlighting the common goal, methods, key results and conclusion. Do not add information that is not in the source texts\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0msummary_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunked_article\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m700\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_splitter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nSummary article number {i}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/2771001906.py\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(article, prompt_0, prompt_1, chunk_size, max_tokens_0, max_tokens_1, text_splitter)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_chunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_chunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mchunk_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqwen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_tokens_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;31m#print(f\"\\nSummary chunk number {i}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m#print(chunk_summary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/458806426.py\u001b[0m in \u001b[0;36mqwen\u001b[0;34m(article, prompt, max_tokens)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         ).to(model.device)\n\u001b[0;32m---> 15\u001b[0;31m         outputs = model.generate(\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m         \u001b[0;31m# 9. Call generation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2564\u001b[0;31m         result = decoding_method(\n\u001b[0m\u001b[1;32m   2565\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2566\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2785\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2787\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;34m\"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         ```\"\"\"\n\u001b[0;32m--> 480\u001b[0;31m         outputs: BaseModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m    481\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m                 \u001b[0;31m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             hidden_states = decoder_layer(\n\u001b[0m\u001b[1;32m    411\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecoder_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# Fully Connected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0minput_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance_epsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":12},{"cell_type":"code","source":"print(\"\\n--- ROUGE Metrics (средние значения) ---\")\nfor key in rouge_list[0].keys():\n    avg = sum(r[key] for r in rouge_list) / len(rouge_list)\n    print(f\"{key}: {avg:.4f}\")\n\navg_bert = sum(bert_list) / len(bert_list)\nprint(f\"\\n--- BERTScore F1 (среднее): {avg_bert:.4f} ---\")\n\navg_sum = sum(l['for_summary'] for l in ldfacts_list) / len(ldfacts_list)\navg_abs = sum(l['for_abstract'] for l in ldfacts_list) / len(ldfacts_list)\n\nprint(f\"\\n--- LongDocFACTScore (средние) ---\")\nprint(f\"Для суммаризаций: {avg_sum:.4f}\")\nprint(f\"Для абстрактов: {avg_abs:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T19:27:53.239745Z","iopub.execute_input":"2026-01-08T19:27:53.240314Z","iopub.status.idle":"2026-01-08T19:27:53.246471Z","shell.execute_reply.started":"2026-01-08T19:27:53.24028Z","shell.execute_reply":"2026-01-08T19:27:53.245617Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"*С text_splitter:*","metadata":{}},{"cell_type":"markdown","source":"я забыл сохранить переменную summaries_list прежде чем запустить следующую ячейку :))))))","metadata":{}},{"cell_type":"code","source":"rouge_list = []\nbert_list = []\nldfacts_list = []\nsummaries_list = []\n\nfor i in range(5):\n    print(f\"\\n=== Статья {i} ===\")\n    #извлекаем чанки, абстракт, названия разделов\n    article_dict = ast.literal_eval(df['dict_test'].iloc[i]) #словарь для i-той статьи \n    chunked_article = list(article_dict.values()) #список чанков\n    # chapters_list = list(article_dict.keys()) #список глав\n    # print('Список разделов')\n    # display(pd.DataFrame(chapters_list))\n    abstract = df['abstract'].iloc[i] \n    article = to_full_text(article_dict) #полный текст статьи с ключами и значениями словаря\n    \n    print(f\"Токенов в статье: {len(tokenizer.encode('\\n'.join(chunked_article)))}\")\n    prompt_0 = \"You're a science editor. Briefly summarize this fragment of the scientific text in original language. Do not add information that is not in the source texts\"\n    prompt_1 = \"You're a science editor. Based on the following summaries of the parts of the article, create a single, coherent and concise summary of the entire scientific article in original language, highlighting the common goal, methods, key results and conclusion. Do not add information that is not in the source texts\"\n    \n    summary_full = summarize(article, prompt_0 = prompt_0, prompt_1 = prompt_1,chunk_size = 1500, max_tokens_0 = 500, max_tokens_1 = 700, text_splitter = True)\n    print(f'\\nSummary article number {i}')\n    print(summary_full)\n    summaries_list.append({\n        'article_id': i,\n        'original_text': article,\n        'abstract': abstract,\n        'summary': summary_full\n    })\n\n    results = rouge.compute(\n    predictions=[summary_full],\n    references=[article],\n    use_stemmer=True\n    )\n    print(\"ROUGE Metrics:\")\n\n    rouge_dict = {}\n    for key, value in results.items():\n        print(f\"{key}: {value:.4f}\")\n        rouge_dict[key] = value\n    rouge_list.append(rouge_dict)\n\n    _, _, F1 = scorer.score([summary_full], [abstract])\n    bert_f1 = F1.item()\n    print(f\"\\nBERTScore: F1 = {bert_f1:.4f}\")\n    bert_list.append(bert_f1)\n\n    ldfacts_sum = ldfacts_scorer.score_src_hyp_long([article], [summary_full])\n    ldfacts_abs = ldfacts_scorer.score_src_hyp_long([article], [abstract])\n    print(f\"LongDocFACTScore for sum: {ldfacts_sum[0]}\")\n    print(f\"LongDocFACTScore for abstract: {ldfacts_abs[0]}\")\n    ldfacts_list.append({\n        'for_summary': ldfacts_sum[0],\n        'for_abstract': ldfacts_abs[0]\n    })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T19:30:42.38999Z","iopub.execute_input":"2026-01-08T19:30:42.390633Z","iopub.status.idle":"2026-01-08T20:01:45.359139Z","shell.execute_reply.started":"2026-01-08T19:30:42.390601Z","shell.execute_reply":"2026-01-08T20:01:45.358344Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n--- ROUGE Metrics (средние значения) ---\")\nfor key in rouge_list[0].keys():\n    avg = sum(r[key] for r in rouge_list) / len(rouge_list)\n    print(f\"{key}: {avg:.4f}\")\n\navg_bert = sum(bert_list) / len(bert_list)\nprint(f\"\\n--- BERTScore F1 (среднее): {avg_bert:.4f} ---\")\n\navg_sum = sum(l['for_summary'] for l in ldfacts_list) / len(ldfacts_list)\navg_abs = sum(l['for_abstract'] for l in ldfacts_list) / len(ldfacts_list)\n\nprint(f\"\\n--- LongDocFACTScore (средние) ---\")\nprint(f\"Для суммаризаций: {avg_sum:.4f}\")\nprint(f\"Для абстрактов: {avg_abs:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T20:02:46.924993Z","iopub.execute_input":"2026-01-08T20:02:46.925314Z","iopub.status.idle":"2026-01-08T20:02:46.932023Z","shell.execute_reply.started":"2026-01-08T20:02:46.925286Z","shell.execute_reply":"2026-01-08T20:02:46.931315Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"![image.png](attachment:196635df-7b8f-4f75-9452-007daee38c93.png)","metadata":{},"attachments":{"196635df-7b8f-4f75-9452-007daee38c93.png":{"image/png":"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"}}},{"cell_type":"markdown","source":"различия несущественные, но эти метрики все равно неинформативны","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}